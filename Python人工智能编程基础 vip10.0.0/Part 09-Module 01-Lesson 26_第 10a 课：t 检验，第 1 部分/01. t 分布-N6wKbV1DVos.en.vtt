WEBVTT
Kind: captions
Language: en

00:00:00.800 --> 00:00:04.658
Welcome back. In all these cases up to now, we've assumed that we know the

00:00:04.658 --> 00:00:10.438
population parameters, mu and sigma. But much of the time, we don't. We often

00:00:10.438 --> 00:00:16.350
only have samples, which we must then use to draw all our conclusions. In the

00:00:16.350 --> 00:00:19.427
next two lessons, we'll use samples to find out how different a sample mean is

00:00:19.427 --> 00:00:24.690
from a population, and how different two samples are from each other. Out of

00:00:24.690 --> 00:00:28.718
all the measures of center, we usually use the mean. Now, the two samples we're

00:00:28.718 --> 00:00:33.904
comparing in this case, can either be dependent or independent. We'll go over

00:00:33.904 --> 00:00:39.717
these differences later. In lesson ten, we're going to look at these. And then

00:00:39.717 --> 00:00:44.304
in lesson 11, we'll look at independent samples. It's going to be fun. When we

00:00:44.304 --> 00:00:48.525
work with samples, we have to estimate the population standard deviation using

00:00:48.525 --> 00:00:53.970
the samples standard deviation with Bessel's correction. Remember this from

00:00:53.970 --> 00:00:57.640
Lesson 4? Normally, to find out how typical or atypical a sample mean is, in

00:00:57.640 --> 00:01:00.880
what you did before, as we would find its location on the distribution of

00:01:00.880 --> 00:01:05.728
sample means, the sampling distribution. And we can determine the shape and

00:01:05.728 --> 00:01:09.220
parameters of this sampling distribution if we know the population parameters.

00:01:09.220 --> 00:01:14.708
Remember that for any sample mean, we can find where it falls on this

00:01:14.708 --> 00:01:21.395
distribution by standardizing. In other words, finding the z-score of the

00:01:21.395 --> 00:01:25.252
sample mean. We find the difference between the sample mean and mu, and then

00:01:25.252 --> 00:01:29.850
divide by the standard error. But now, the standard error depends on the

00:01:29.850 --> 00:01:35.431
sample, we can no longer us sigma if we have a sample. Therefore, we end up

00:01:35.431 --> 00:01:41.720
with a new distribution that is more prone to error. This is called the t

00:01:41.720 --> 00:01:46.140
distribution. Since it's more prone to error, then it's more spread out and

00:01:46.140 --> 00:01:51.989
thicker in the tails than a normal distribution. Remember from lesson seven

00:01:51.989 --> 00:01:55.116
when you learned that larger sample sizes result in skinnier sampling

00:01:55.116 --> 00:02:00.938
distributions? That same principal applies here. So what do you think happens

00:02:00.938 --> 00:02:06.690
as n, the sample size, increases? The standard error increases? The

00:02:06.690 --> 00:02:11.534
t-distribution approaches a normal distribution? The t-distribution gets

00:02:11.534 --> 00:02:17.862
skinnier tails? And finally, s, the sample center deviation, approaches sigma.

