WEBVTT
Kind: captions
Language: pt-BR

00:00:00.676 --> 00:00:03.167
Vamos conferir a parte
feedforward primeiro.

00:00:03.774 --> 00:00:05.706
Para facilitar
nossos cálculos,

00:00:05.739 --> 00:00:08.087
vamos decidir ter n inputs,

00:00:08.696 --> 00:00:11.124
três neurônios
em uma única camada oculta

00:00:11.457 --> 00:00:13.122
e dois outputs.

00:00:13.464 --> 00:00:15.085
Aliás, na prática,

00:00:15.118 --> 00:00:18.385
podemos ter milhares de neurônios
em uma só camada oculta.

00:00:18.808 --> 00:00:22.896
Podemos usar W1 como
o conjunto de pesos, de x até h

00:00:22.929 --> 00:00:27.046
e W2 como o conjunto de pesos
de h até y.

00:00:27.663 --> 00:00:29.798
Como temos apenas
uma camada oculta,

00:00:30.081 --> 00:00:34.082
teremos só dois passos
em cada ciclo de feedforward.

00:00:34.597 --> 00:00:38.533
O passo 1 será encontrar h
a partir de um input dado

00:00:38.865 --> 00:00:41.013
e o conjunto de pesos W1.

00:00:41.819 --> 00:00:44.702
O passo 2 será encontrar
o output y

00:00:45.390 --> 00:00:49.679
a partir do h calculado
e o conjunto de pesos W2.

00:00:51.275 --> 00:00:55.352
Você vai descobrir que, além do uso
de funções de ativação não-lineares,

00:00:55.759 --> 00:00:58.836
todos os cálculos envolvem
combinações lineares

00:00:59.137 --> 00:01:01.011
de inputs e pesos.

00:01:01.279 --> 00:01:04.979
Em outras palavras, vamos usar
multiplicação de matrizes.

00:01:06.144 --> 00:01:09.792
Vamos começar com o passo 1:
encontrar h.

00:01:10.225 --> 00:01:13.710
Repare que, se tivermos mais
de um neurônio na camada oculta,

00:01:13.743 --> 00:01:15.150
que geralmente é o caso,

00:01:15.386 --> 00:01:17.055
h é na verdade um vetor.

00:01:17.834 --> 00:01:20.333
Temos nossos
inputs iniciais, x,

00:01:20.366 --> 00:01:22.409
e x também é um vetor.

00:01:22.942 --> 00:01:26.564
Queremos achar o valor
dos neurônios ocultos, h.

00:01:27.013 --> 00:01:29.526
Cada input se conecta
a cada neurônio

00:01:29.559 --> 00:01:30.724
na camada oculta.

00:01:31.354 --> 00:01:32.688
Para simplificar,

00:01:32.721 --> 00:01:34.826
vamos usar
os seguintes índices:

00:01:34.859 --> 00:01:38.750
W11 conecta x1 com h1,

00:01:39.169 --> 00:01:42.545
W13 conecta x1 com h3,

00:01:43.114 --> 00:01:47.117
W21 conecta x2 com h1,

00:01:47.391 --> 00:01:51.611
Wn3 conecta xn com h3

00:01:52.021 --> 00:01:53.222
e assim por diante.

00:01:55.461 --> 00:02:00.749
O vetor dos inputs
x1, x2... até xn

00:02:00.973 --> 00:02:04.572
é multiplicado pela matriz
dos pesos, W1,

00:02:04.927 --> 00:02:07.107
para nos dar
os neurônios ocultos.

00:02:08.279 --> 00:02:09.933
Então cada vetor h

00:02:10.459 --> 00:02:11.997
é igual ao vetor x

00:02:12.620 --> 00:02:16.314
multiplicado
pela matriz peso W1.

00:02:16.347 --> 00:02:19.912
Neste caso, temos uma matriz peso
com n linhas,

00:02:19.945 --> 00:02:22.406
pois temos n inputs,

00:02:22.741 --> 00:02:24.098
e três colunas,

00:02:24.246 --> 00:02:27.204
pois temos 3 neurônios
na camada oculta.

00:02:27.618 --> 00:02:30.992
Se você multiplicar o vetor
de input pela matriz peso,

00:02:31.389 --> 00:02:35.923
terá uma combinação linear simples
para cada neurônio na camada oculta

00:02:36.417 --> 00:02:38.272
nos dando o vetor h.

00:02:38.846 --> 00:02:40.311
Então, por exemplo,

00:02:40.895 --> 00:02:45.020
h1 será igual
a x1 vezes W11

00:02:45.166 --> 00:02:49.555
+ x2 vezes W21
e assim por diante.

00:02:50.165 --> 00:02:53.160
Mas ainda não acabamos
de calcular a camada oculta.

00:02:53.996 --> 00:02:56.555
Reparou no símbolo de linha
que estou usando?

00:02:56.875 --> 00:03:00.599
Usei para lembrar que ainda
não terminamos de achar h.

00:03:00.632 --> 00:03:03.330
Estamos quase lá,
mas ainda não chegamos.

00:03:04.017 --> 00:03:07.121
Para garantir que os v alores de h
não explodam,

00:03:07.154 --> 00:03:09.090
ou fiquem grandes demais,

00:03:09.245 --> 00:03:11.540
precisamos usar
uma função de ativação.

