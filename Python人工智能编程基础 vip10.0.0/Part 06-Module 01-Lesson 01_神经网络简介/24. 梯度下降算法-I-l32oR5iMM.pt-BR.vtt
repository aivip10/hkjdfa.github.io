WEBVTT
Kind: captions
Language: pt-BR

00:00:00.267 --> 00:00:03.300
Agora nós temos as ferramentas
para compor o pseudocódigo

00:00:03.334 --> 00:00:06.534
para o algoritmo
do gradiente descendente.

00:00:07.234 --> 00:00:10.200
Primeiro passo: comece
com pesos aleatórios

00:00:10.234 --> 00:00:13.434
de W1 até WN e B,

00:00:13.467 --> 00:00:17.367
que formarão uma linha que será
a função de probabilidade

00:00:17.400 --> 00:00:20.601
dada pela sigmoide
de WX mais B.

00:00:20.634 --> 00:00:22.868
Para cada ponto,
nós calculamos o erro.

00:00:22.901 --> 00:00:26.200
O erro é grande para os pontos
classificados erroneamente

00:00:26.234 --> 00:00:29.000
e pequeno para os pontos
classificados corretamente.

00:00:29.033 --> 00:00:33.200
Para cada ponto das coordenadas
X1 até XN.

00:00:33.234 --> 00:00:37.434
Nós adaptamos a WI adicionando
a taxa de aprendizado alfa

00:00:37.467 --> 00:00:39.467
vezes o derivativo parcial

00:00:39.501 --> 00:00:42.868
da função de erro
em respeito ao WI.

00:00:42.901 --> 00:00:44.167
Nós atualizamos o B

00:00:44.200 --> 00:00:46.934
adicionando alfa vezes
o derivativo da função de erro

00:00:46.968 --> 00:00:48.367
em respeito a B.

00:00:48.400 --> 00:00:52.467
Nós teremos novos pesos WI'
e novos vieses B'.

00:00:52.501 --> 00:00:55.033
Nós já calculamos
os derivativos parciais

00:00:55.067 --> 00:00:59.133
e sabemos que eles são
Y^ menos Y vezes XI

00:00:59.167 --> 00:01:01.534
para o derivativo de WI,

00:01:01.567 --> 00:01:05.133
e Y^ menos Y
para o derivativo de B.

00:01:05.167 --> 00:01:07.501
É assim que atualizamos
os pesos.

00:01:10.300 --> 00:01:13.701
Nós repetimos o processo
até que o erro seja pequeno.

00:01:13.734 --> 00:01:15.801
Podemos repetir
várias etapas,

00:01:15.834 --> 00:01:18.801
que são chamadas de epochs,
que veremos posteriormente.

00:01:18.834 --> 00:01:21.868
Isso parece familiar.
Já vimos isso antes?

00:01:21.901 --> 00:01:25.834
Cada ponto adiciona
um múltiplo de si mesmo

00:01:25.868 --> 00:01:27.167
aos pesos da linha

00:01:27.200 --> 00:01:29.567
para que a linha se aproxime,

00:01:29.601 --> 00:01:31.701
caso tenha sido
classificado erroneamente.

00:01:31.734 --> 00:01:34.634
É isso que o algoritmo
perceptron fez.

00:01:34.667 --> 00:01:36.901
No próximo vídeo,
veremos as semelhanças,

00:01:36.934 --> 00:01:39.033
pois a semelhança
é suspeita.

